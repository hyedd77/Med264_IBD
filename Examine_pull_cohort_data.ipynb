{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext google.cloud.bigquery\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#skeleton code below is used to read csv's that have been written to workspace storage  \n",
    " # Get ehr data from workspace bucket\n",
    "name_of_file_in_bucket = 'colitis_updated.csv'\n",
    "\n",
    "# get the bucket name\n",
    "my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "\n",
    "# copy csv file from the bucket to the current working space\n",
    "os.system(f\"gsutil cp '{my_bucket}/data/{name_of_file_in_bucket}' .\")\n",
    "\n",
    "# read in csv\n",
    "colitis = pd.read_csv(name_of_file_in_bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########reading in colitis + cancer table\n",
    "name_of_file_in_bucket = 'crc_and_colitis_pts.csv'\n",
    "\n",
    "# get the bucket name\n",
    "my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "\n",
    "# copy csv file from the bucket to the current working space\n",
    "os.system(f\"gsutil cp '{my_bucket}/data/{name_of_file_in_bucket}' .\")\n",
    "\n",
    "# read in csv\n",
    "crc_and_colitis = pd.read_csv(name_of_file_in_bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull data in 'person', 'concept', and 'survey' tables \n",
    "\n",
    "####add indicator column for outcome\n",
    "colitis['crc_yes'] = 0\n",
    "\n",
    "colitis.loc[colitis['person_id'].isin(crc_and_colitis['person_id']), 'crc_yes'] = 1\n",
    "\n",
    "len(colitis[colitis['crc_yes'] == 1]['person_id'].unique()) #sanity check, should equal 168"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = os.getenv(\"WORKSPACE_CDR\")\n",
    "CDR_split=dataset.split(\".\")\n",
    "CDR_version=CDR_split[1]\n",
    "prefix = CDR_split[0]\n",
    "\n",
    "#prefix\n",
    "CDR_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###testing SQL syntax\n",
    "test_query = '''\n",
    "SELECT *\n",
    "FROM fc-aou-cdr-prod-ct.C2022Q4R9.observation\n",
    "WHERE value_as_string != 'None'\n",
    "LIMIT 1000\n",
    "'''\n",
    "\n",
    "test_df = pd.read_gbq(test_query, dialect=\"standard\")\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####get demographics\n",
    "ids_list = colitis['person_id'].unique()\n",
    "person_query = '''\n",
    "SELECT \n",
    "        person.person_id,\n",
    "        g_concept.concept_name as gender, \n",
    "        person.birth_datetime as date_of_birth,\n",
    "        r_concept.concept_name as race,\n",
    "        e_concept.concept_name as ethnicity,\n",
    "        s_concept.concept_name as birth_sex\n",
    "    FROM\n",
    "        fc-aou-cdr-prod-ct.C2022Q4R9.person as person\n",
    "    LEFT JOIN\n",
    "        (SELECT concept_id, concept_name FROM fc-aou-cdr-prod-ct.C2022Q4R9.concept) as g_concept\n",
    "        ON person.gender_concept_id = g_concept.concept_id \n",
    "    LEFT JOIN \n",
    "        (SELECT concept_id, concept_name FROM fc-aou-cdr-prod-ct.C2022Q4R9.concept) as r_concept\n",
    "        ON person.race_concept_id = r_concept.concept_id \n",
    "    LEFT JOIN \n",
    "        (SELECT concept_id, concept_name FROM fc-aou-cdr-prod-ct.C2022Q4R9.concept) as e_concept\n",
    "        ON person.ethnicity_concept_id = e_concept.concept_id\n",
    "    LEFT JOIN \n",
    "        (SELECT concept_id, concept_name FROM fc-aou-cdr-prod-ct.C2022Q4R9.concept) as s_concept\n",
    "        ON person.sex_at_birth_concept_id = s_concept.concept_id\n",
    "    WHERE \n",
    "        person.person_id IN ({})\n",
    "        '''.format(', '.join(map(str, ids_list)))\n",
    "\n",
    "demo_df = pd.read_gbq(person_query, dialect=\"standard\")\n",
    "demo_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####get survey data\n",
    "survey_query='''\n",
    "SELECT\n",
    "        ds_survey.person_id,\n",
    "        ds_survey.survey_datetime,\n",
    "        ds_survey.survey,\n",
    "        ds_survey.question_concept_id,\n",
    "        ds_survey.question,\n",
    "        ds_survey.answer_concept_id,\n",
    "        ds_survey.answer,\n",
    "FROM fc-aou-cdr-prod-ct.C2022Q4R9.ds_survey as ds_survey\n",
    "WHERE\n",
    "        (\n",
    "            question_concept_id IN (\n",
    "                SELECT\n",
    "                    DISTINCT concept_id \n",
    "                FROM\n",
    "                    fc-aou-cdr-prod-ct.C2022Q4R9.cb_criteria as c\n",
    "                JOIN\n",
    "                    (\n",
    "                        select\n",
    "                            cast(cr.id as string) as id \n",
    "                        FROM\n",
    "                            fc-aou-cdr-prod-ct.C2022Q4R9.cb_criteria as cr \n",
    "                        WHERE\n",
    "                            concept_id IN (\n",
    "                                1586134,1585855,1585710,43528895,40192389,1740639\n",
    "                            ) \n",
    "                            AND domain_id = 'SURVEY'\n",
    "                    ) a \n",
    "                        ON (\n",
    "                            c.path like CONCAT('%',\n",
    "                        a.id,\n",
    "                        '.%')) \n",
    "                    WHERE\n",
    "                        domain_id = 'SURVEY' \n",
    "                        AND type = 'PPI' \n",
    "                        AND subtype = 'QUESTION'\n",
    "                    )\n",
    "            )  \n",
    "AND person_id IN ({})'''.format(', '.join(map(str, ids_list)))\n",
    "\n",
    "surv_df = pd.read_gbq(survey_query, dialect=\"standard\")\n",
    "surv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ses_query = '''\n",
    " SELECT\n",
    "        observation.person_id,\n",
    "        observation.observation_datetime,\n",
    "        zip_code.zip3_as_string as zip_code,\n",
    "        zip_code.fraction_assisted_income as assisted_income,\n",
    "        zip_code.fraction_high_school_edu as high_school_education,\n",
    "        zip_code.median_income,\n",
    "        zip_code.fraction_no_health_ins as no_health_insurance,\n",
    "        zip_code.fraction_poverty as poverty,\n",
    "        zip_code.fraction_vacant_housing as vacant_housing,\n",
    "        zip_code.deprivation_index,\n",
    "        zip_code.acs as american_community_survey_year \n",
    "    FROM\n",
    "        fc-aou-cdr-prod-ct.C2022Q4R9.zip3_ses_map as zip_code \n",
    "    JOIN\n",
    "        fc-aou-cdr-prod-ct.C2022Q4R9.observation as observation \n",
    "            ON CAST(SUBSTR(observation.value_as_string,\n",
    "        0,\n",
    "        STRPOS(observation.value_as_string,\n",
    "        '*') - 1) AS INT64) = zip_code.zip3 \n",
    "    WHERE \n",
    "        observation_source_concept_id = 1585250 \n",
    "        AND observation.value_as_string NOT LIKE 'Res%'\n",
    "        AND person_id IN ({})'''.format(', '.join(map(str, ids_list)))\n",
    "\n",
    "ses_df = pd.read_gbq(ses_query, dialect=\"standard\")\n",
    "ses_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writing demographics file \n",
    "\n",
    "# Replace df with THE NAME OF YOUR DATAFRAME\n",
    "my_dataframe = demo_df  \n",
    "\n",
    "\n",
    "# Replace 'test.csv' with THE NAME of the file you're going to store in the bucket (don't delete the quotation marks)\n",
    "destination_filename = 'demographics.csv'\n",
    "\n",
    "########################################################################\n",
    "##\n",
    "################# DON'T CHANGE FROM HERE ###############################\n",
    "##\n",
    "########################################################################\n",
    "\n",
    "# save dataframe in a csv file in the same workspace as the notebook\n",
    "my_dataframe.to_csv(destination_filename, index=False)\n",
    "\n",
    "# get the bucket name\n",
    "my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "\n",
    "# copy csv file to the bucket\n",
    "args = [\"gsutil\", \"cp\", f\"./{destination_filename}\", f\"{my_bucket}/data/\"]\n",
    "output = subprocess.run(args, capture_output=True)\n",
    "\n",
    "# print output from gsutil\n",
    "output.stderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This snippet assumes you run setup first\n",
    "\n",
    "# This code saves your dataframe into a csv file in a \"data\" folder in Google Bucket\n",
    "\n",
    "# Replace df with THE NAME OF YOUR DATAFRAME\n",
    "my_dataframe = surv_df  \n",
    "\n",
    "\n",
    "# Replace 'test.csv' with THE NAME of the file you're going to store in the bucket (don't delete the quotation marks)\n",
    "destination_filename = 'surveys.csv'\n",
    "\n",
    "########################################################################\n",
    "##\n",
    "################# DON'T CHANGE FROM HERE ###############################\n",
    "##\n",
    "########################################################################\n",
    "\n",
    "# save dataframe in a csv file in the same workspace as the notebook\n",
    "my_dataframe.to_csv(destination_filename, index=False)\n",
    "\n",
    "# get the bucket name\n",
    "my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "\n",
    "# copy csv file to the bucket\n",
    "args = [\"gsutil\", \"cp\", f\"./{destination_filename}\", f\"{my_bucket}/data/\"]\n",
    "output = subprocess.run(args, capture_output=True)\n",
    "\n",
    "# print output from gsutil\n",
    "output.stderr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This snippet assumes you run setup first\n",
    "\n",
    "# This code saves your dataframe into a csv file in a \"data\" folder in Google Bucket\n",
    "\n",
    "# Replace df with THE NAME OF YOUR DATAFRAME\n",
    "my_dataframe = ses_df \n",
    "\n",
    "\n",
    "# Replace 'test.csv' with THE NAME of the file you're going to store in the bucket (don't delete the quotation marks)\n",
    "destination_filename = 'ses.csv'\n",
    "\n",
    "########################################################################\n",
    "##\n",
    "################# DON'T CHANGE FROM HERE ###############################\n",
    "##\n",
    "########################################################################\n",
    "\n",
    "# save dataframe in a csv file in the same workspace as the notebook\n",
    "my_dataframe.to_csv(destination_filename, index=False)\n",
    "\n",
    "# get the bucket name\n",
    "my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "\n",
    "# copy csv file to the bucket\n",
    "args = [\"gsutil\", \"cp\", f\"./{destination_filename}\", f\"{my_bucket}/data/\"]\n",
    "output = subprocess.run(args, capture_output=True)\n",
    "\n",
    "# print output from gsutil\n",
    "output.stderr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####examining distinct surveys  \n",
    "#skeleton code below is used to read csv's that have been written to workspace storage  \n",
    " # Get ehr data from workspace bucket\n",
    "name_of_file_in_bucket = 'surveys.csv'\n",
    "\n",
    "# get the bucket name\n",
    "my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "\n",
    "# copy csv file from the bucket to the current working space\n",
    "os.system(f\"gsutil cp '{my_bucket}/data/{name_of_file_in_bucket}' .\")\n",
    "\n",
    "# read in csv\n",
    "surv_df = pd.read_csv(name_of_file_in_bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "##question buckets\n",
    "q_ducket = surv_df['survey'].unique()\n",
    "print(q_ducket)\n",
    "family_q = surv_df[surv_df['survey']=='Personal and Family Health History']['question'].unique()\n",
    "basic_q = surv_df[surv_df['survey']=='The Basics']['question'].unique()\n",
    "lifestyle_q = surv_df[surv_df['survey']=='Lifestyle']['question'].unique()\n",
    "overall_health_q = surv_df[surv_df['survey']=='Overall Health']['question'].unique()\n",
    "social_questions = surv_df[surv_df['survey']=='Social Determinants of Health']['question'].unique()\n",
    "access_q = surv_df[surv_df['survey']=='Healthcare Access & Utilization']['question'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lifestyle_q)\n",
    "###include: Smoking: Smoke Frequency, Alchohol: Average Daily Drink Count, Past 3 Month Frequency*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(overall_health_q)\n",
    "###Overall Health: Social Satisfaction, General Mental, General Physical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(access_q)\n",
    "#Delayed Medical Care, Can't Afford Care "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(family_q)\n",
    "gi_search = ['colitis', 'bowel syndrome', 'Crohn', 'colon', 'gastro', 'intestine', 'rect']\n",
    "\n",
    "trimmed_q = []\n",
    "for s in family_q:\n",
    "    for p in gi_search:\n",
    "        if p in s and 'Including yourself' in s:\n",
    "            trimmed_q.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "family_history = list(set(trimmed_q))\n",
    "family_history\n",
    "\n",
    "relevant_q = family_history+['Overall Health: Social Satisfaction', 'Overall Health: General Mental Health', 'Overall Health: General Physical Health','Delayed Medical Care', 'Can\\'t Afford Care','food would run out', 'doctor or nurse act as if he or she thinks you are not smart', 'doctor or nurse is not listening', 'Smoking: Smoke Frequency', 'Alcohol: Average Daily Drink Count', 'Past 3 Month Use Frequency']\n",
    "relevant_q\n",
    "surv_df[surv_df['question'] == 'Including yourself, who in your family has had Crohn\\'s disease? Select all that apply.']\n",
    "'|'.join(relevant_q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "mask = surv_df['question'].str.contains(re.escape('Including yourself, who in your family has had Crohn\\'s disease? Select all that apply.'), case=False)\n",
    "#print(mask)\n",
    "\n",
    "surv_df_test = surv_df[mask]\n",
    "\n",
    "surv_df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####filtering relevant survey questions\n",
    "mask = surv_df['question'].str.contains('|'.join(re.escape(q) for q in relevant_q), case=False)\n",
    "#print(mask)\n",
    "\n",
    "surv_df_fil = surv_df[mask]\n",
    "\n",
    "surv_df_fil['question'].unique()\n",
    "\n",
    "###dropping -Self answers from family history\n",
    "mask = ~surv_df_fil['answer'].str.contains('- Self', case=False)\n",
    "#print(mask)\n",
    "\n",
    "surv_df_fil = surv_df_fil[mask]\n",
    "\n",
    "surv_df_fil['question'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trim_surv = surv_df_fil[['person_id', 'question', 'answer']]\n",
    "print(len(trim_surv))\n",
    "trim_surv = trim_surv.drop_duplicates(subset=['person_id', 'question'])\n",
    "trim_surv = trim_surv.reset_index(drop=True)\n",
    "surv_wide = trim_surv.pivot(index='person_id',columns='question',values='answer')\n",
    "\n",
    "def extract_colon(cell):\n",
    "    if isinstance(cell, str) and ':' in cell:\n",
    "        return cell.split(':', 1)[-1].strip()\n",
    "    else:\n",
    "        return cell\n",
    "\n",
    "surv_wide = surv_wide.applymap(extract_colon)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collapse_columns(row):\n",
    "    cant_afford_columns = surv_wide.filter(like=\"Can't\").columns\n",
    "    if any(row[col] == 'Yes' for col in cant_afford_columns):\n",
    "        return 'yes'\n",
    "    elif all(pd.isna(row[col]) or row[col] == 'NA' for col in cant_afford_columns):\n",
    "        return 'NA'\n",
    "    else:\n",
    "        return 'no'\n",
    "    \n",
    "def collapse_delay_columns(row):\n",
    "    delayed_care_columns = surv_wide.filter(like=\"Delayed\").columns\n",
    "    if any(row[col] == 'Yes' for col in delayed_care_columns):\n",
    "        return 'yes'\n",
    "    elif all(pd.isna(row[col]) or row[col] == 'NA' for col in delayed_care_columns):\n",
    "        return 'NA'\n",
    "    else:\n",
    "        return 'no'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cant_afford_columns = surv_wide.filter(like=\"Can't\").columns\n",
    "\n",
    "surv_wide[\"Can't afford full medical care\"] = surv_wide[cant_afford_columns].apply(collapse_columns, axis=1)\n",
    "surv_wide = surv_wide.drop(columns=cant_afford_columns)\n",
    "\n",
    "delayed_care_columns = surv_wide.filter(like=\"Delayed\").columns\n",
    "\n",
    "surv_wide[\"Delayed medical care\"] = surv_wide[delayed_care_columns].apply(collapse_delay_columns, axis=1)\n",
    "surv_wide = surv_wide.drop(columns=delayed_care_columns)\n",
    "\n",
    "surv_wide[\"Can't afford full medical care\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####examining distinct surveys to find relevant indicators \n",
    "#skeleton code below is used to read csv's that have been written to workspace storage  \n",
    " # Get ehr data from workspace bucket\n",
    "name_of_file_in_bucket = 'demographics.csv'\n",
    "\n",
    "# get the bucket name\n",
    "my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "\n",
    "# copy csv file from the bucket to the current working space\n",
    "os.system(f\"gsutil cp '{my_bucket}/data/{name_of_file_in_bucket}' .\")\n",
    "\n",
    "# read in csv\n",
    "demo_df = pd.read_csv(name_of_file_in_bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####examining distinct surveys to find relevant indicators \n",
    "#skeleton code below is used to read csv's that have been written to workspace storage  \n",
    " # Get ehr data from workspace bucket\n",
    "name_of_file_in_bucket = 'ses.csv'\n",
    "\n",
    "# get the bucket name\n",
    "my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "\n",
    "# copy csv file from the bucket to the current working space\n",
    "os.system(f\"gsutil cp '{my_bucket}/data/{name_of_file_in_bucket}' .\")\n",
    "\n",
    "# read in csv\n",
    "ses_df = pd.read_csv(name_of_file_in_bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ses_df.head()\n",
    "\n",
    "ses_unneeded = ['observation_datetime', 'zip_code', 'high_school_education', 'vacant_housing', 'american_community_survey_year']\n",
    "\n",
    "ses_df = ses_df.drop(columns = ses_unneeded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colitis['cancer_yes'] = colitis['age_at_crc_dx'].notna().astype(int)\n",
    "colitis_final = colitis[['person_id','age_at_colitis_dx', 'uc1_crohns2', 'cancer_yes']]\n",
    "\n",
    "sum(colitis_final['cancer_yes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_demo = pd.merge(colitis_final, demo_df.drop(columns=['date_of_birth']), on='person_id', how='left')\n",
    "w_ses = pd.merge(w_demo, ses_df, on='person_id', how='left')\n",
    "final = pd.merge(w_ses, surv_wide, on='person_id', how='left')\n",
    "final.shape\n",
    "#len(final['person_id'].unique())\n",
    "\n",
    "for col in final.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This snippet assumes you run setup first\n",
    "\n",
    "# This code saves your dataframe into a csv file in a \"data\" folder in Google Bucket\n",
    "\n",
    "# Replace df with THE NAME OF YOUR DATAFRAME\n",
    "my_dataframe = final \n",
    "\n",
    "\n",
    "# Replace 'test.csv' with THE NAME of the file you're going to store in the bucket (don't delete the quotation marks)\n",
    "destination_filename = 'final_dataset.csv'\n",
    "\n",
    "########################################################################\n",
    "##\n",
    "################# DON'T CHANGE FROM HERE ###############################\n",
    "##\n",
    "########################################################################\n",
    "\n",
    "# save dataframe in a csv file in the same workspace as the notebook\n",
    "my_dataframe.to_csv(destination_filename, index=False)\n",
    "\n",
    "# get the bucket name\n",
    "my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "\n",
    "# copy csv file to the bucket\n",
    "args = [\"gsutil\", \"cp\", f\"./{destination_filename}\", f\"{my_bucket}/data/\"]\n",
    "output = subprocess.run(args, capture_output=True)\n",
    "\n",
    "# print output from gsutil\n",
    "output.stderr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
